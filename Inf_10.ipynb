{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMTGfatpSCZLJby8/HeAdXY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nikolay1982Nikolaev/Inferential-Statistics-Bicocca/blob/main/Inf_10.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Asymtotic Evaluation\n",
        "\n"
      ],
      "metadata": {
        "id": "Jo6ljvMXbQy5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Point estimation"
      ],
      "metadata": {
        "id": "0e0R5ioLbQ1l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Consistency\n",
        "\n",
        "Def: 10.1.1. A sequence of estimators $W_n = W_n(X_...X_n)$ is a *consistentsequence of estimators*  of the parameter $\\theta$ , if for every $\\epsilon > 0$ and every $\\theta \\in \\Theta$\n",
        "\n",
        "$$lim_{n->\\infty} P_{\\theta}(|W_n - \\theta|< \\epsilon)= 1$$\n",
        "\n",
        "Theorem: 10.1.3. If $W_n$ is a seqeunce of estimators of a parameter $\\theta$ satisfying\n",
        "- $lim_{n->\\infty} Var_{\\theta}[W_n]= 0$\n",
        "- $lim_{n->\\infty} Bias_{\\theta}[W_n]= 0$\n",
        "\n",
        "for every $\\theta \\in \\Theta$ then $W_n$ is a consistent sequence of estimators of $\\theta$.\n",
        "\n",
        "Theorem: 10.1.5. $Let $W_n$ be a consisten sequence of estimators of a parameter $\\theta$. Let $a_1, a_2...$ and $b_1, b_2...$ be sequence of constants satisfying\n",
        "- $lim_{n->\\infty} a_n = 1$\n",
        "- $lim_{n->\\infty} b_n = 0$\n",
        "\n",
        "Then the sequence $U_n = a_n W_n + b_n$ is a consistent sequence of estimators of $\\theta$\n",
        "\n",
        "Theorem: 10.1.6. COnsistency of MLEs- Let $X_1,X_2...$ be iid $f((x|\\theta)$ and let $L(\\theta|x)= \\prod_{i=1}^n f(x_i|\\theta)$ be the likelihhod function. Let $\\hat{\\theta}$ denote the MLE of $\\theta$. Let $\\tau(\\theta)$ be a continuous function of $\\theta$. Under the regularity conditions in Miscellanea 10.6.2. of $f(x|\\theta)$ and , hence $L(\\theta|x)$ for every $\\epsilon> 0$ and every $\\theta \\in \\Theta$\n",
        "\n",
        "$$lim_{n->\\infty} P_{\\theta}(|\\tau(\\hat{\\theta})- \\tau(\\theta)|\\geq \\epsilon)= 0$$\n",
        "\n",
        "That is, $\\tau(\\hat{\\theta})$ is a consistent estimator of $\\tau(\\theta)$\n",
        "\n",
        "Proof:"
      ],
      "metadata": {
        "id": "rrJdPyERbQ4B"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Efficiency\n",
        "\n",
        "Def: 10.1.7. For an estimator $T_n$, if $lim_{n->\\infty} k_n Var[T_n]= \\tau^2 < \\infty$ , where $[k_n]$  is a sequence of constants, then $\\tau^2$ is called the *limiting variance or limit of the variances*\n",
        "\n",
        "Ex: 10.1.8. Limiting variance\n",
        "Definition:10.1.9. For an estimator $T_n$, suppose that $k_n(T_n - \\tau(\\theta))-> N(0, \\sigma^2)$ in distribution. The parameter $\\sigma^2$\n",
        " is called the asymptotic variance or variance of the limit distribution of $T_n$\n",
        "\n",
        " ex. 10.1.10 Large - sample mixture variance\n",
        "\n",
        ""
      ],
      "metadata": {
        "id": "fXU2wgiEbQ6g"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "def: 10.1.11. A sequence of estimators $W_n$ is asymptotic efficient for a parameter $\\tau(\\theta)$ if $\\sqrt{n}[W_n-\\tau(\\theta)]-> N(0, Î½(\\theta))$ in distribution and\n",
        "\n",
        "$$\\nu(\\theta)= \\frac{[\\tau'(\\theta)]^2}{E_{\\theta((\\frac{\\partial}{\\partial} log(f(X|\\theta)))^2)}} $$\n",
        "\n",
        "That is, the asymptotic variance of $W_n$ achieves the Cramer-Rao Lower Band\n",
        "\n",
        "Theorem: 10.1.12 Asymptotic efficenty of MLEs- Let $X_1,X_2...$ be IID $f(x|\\theta)$ let $\\hat{\\theta}$ denote the MLE of $\\theta$, and let $\\tau(\\theta)$ be a continuous function of $\\theta$. Under the regularity conditions in Miscellanea 10.6.2. on $f(x|\\theta)$ and hence $L(\\theta|x)$\n",
        "\n",
        "$$\\sqrt{n}(\\tau(\\hat{\\theta})- \\tau(\\theta))-> N(0, \\nu(\\theta))$$\n",
        "where $\\nu(\\theta)$ is the Cramer-Rao Lower Bound. That is $\\tau(\\hat{\\theta})$ is a consistent and aymptotically efficient estimator of $\\\n",
        "tau(\\theta)$\n",
        "\n",
        "Proof:\n",
        "\n",
        "Ex: 10.1.13: Asymptotic normality and consitency\n",
        "\n"
      ],
      "metadata": {
        "id": "1Mo2I5ucbQ87"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### calculations and CXomparisons\n",
        "\n",
        "ex: 10.1.14. Approximate binomial variance\n",
        "\n",
        "ex: 10.1.15.\n",
        "\n",
        "De: 10.1.16. If two estimators $W_n, V_n$ satisfy\n",
        "$$\\sqrt{n}[W_n - \\tau(\\theta)] -> N(0, \\sigma_W^2)$$\n",
        "$$\\sqrt{n}[V_n - \\tau(\\theta)] -> N(0, \\sigma_V^2)$$\n",
        "\n",
        "in distribution, the asymptotic relative efficency ARE of $V_n$ with respect to $W_n$ is $$ARE(V_n, W_n)= \\frac{\\sigma_W^2}{\\sigma_V^2}$$\n",
        "\n",
        "Ex: 10.1.17 ARs of Poisson estimators\n",
        "\n",
        "ex: 10.1.18: estimating a gamma mean\n",
        "\n"
      ],
      "metadata": {
        "id": "-eyeDTjrbQ_J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Bootstrap Standard Errors:\n",
        "\n",
        "ex: 10.1.19: Bootstrapping a variance\n",
        "\n",
        "ex: 10.1.20: bootstrapping a binomial variance\n",
        "\n",
        "Ex: 10.1.22. Parametric Bootstrap:\n",
        "\n"
      ],
      "metadata": {
        "id": "0VFic3rdbRBV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Robustnes:\n",
        "\n"
      ],
      "metadata": {
        "id": "KU3uYsEFbRDk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### The Mean and the Median:\n",
        "\n",
        "ex: 10.2.1. Robustnes of the sample mean:\n",
        "\n",
        "def: 10.2.2. Let $X_{(1)} < ...< X_{(n)}$ be an ordered sample of size n, and let $T_n$ be a statistic based on this sample. $T_n$ has breakdown value $b, 0\\leq b \\leq 1$, if for every $\\epsilon > 0$\n",
        "\n",
        "$$lim_{X_{((1-b)n)}-> \\infty} T_n <\\infty$$\n",
        "\n",
        "and\n",
        "\n",
        "$$lim_{X_{((1-(b+\\epsilon))n)}-> \\infty} T_n =\\infty$$\n",
        "\n",
        "recal def 5.4.2.\n",
        "\n",
        "Ex: 10.2.3. Asymptotic normality of the median\n",
        "\n",
        "ex: 10.2.4. AREs of the median to the mean\n",
        "\n"
      ],
      "metadata": {
        "id": "9fmPTiSjbRF4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### M-estimators:\n",
        "\n",
        "Ex: 10.2.5. Huber Estimator:\n",
        "\n",
        "Ex: 10.2.6. Limity distribution of the Huber estimator\n",
        "\n",
        "ex: 10.2.7. ARE of the HUner estimator\n",
        "\n"
      ],
      "metadata": {
        "id": "AmuVwJCZbRH9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Hypothesis testing:\n",
        "\n"
      ],
      "metadata": {
        "id": "mhyRFFNCbRKL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Asybtitic Distribution of LRTs\n",
        "\n",
        "Theorem: 10.3.1. Asymptotic distribution of the LRT- simple $H_0$.. For testing $H_0: \\theta=\\theta_0$ versus $H_1:\\theta \\ne \\theta_0$ suppose $X_1...X_n$ are iid $f(x|\\theta), \\hat{\\theta}$ is the MLE of $\\theta$ and $f(x|\\theta)$ satisfies the regularity conditons in Miscellanea 10.6.2. . Then under $H_0$ as $n-> \\infty$\n",
        "\n",
        "$$-2 log(\\lambda(X))-\\xhi_1^2$$ in distribution\n",
        "\n",
        "whre $\\chi_1^2$ is a chi random variable with 1 df\n",
        "\n",
        "Proof:\n",
        "\n",
        "Ex: 10.3.2. Poisson LRT\n",
        "\n",
        "Theorem: 10.3.3. Let $X_1...X_n$ be a random sample from a pdf or pmf $f(x|\\theta)$. Under the regularoty conditions in Miscellanea 10.6.2. if $\\theta\\in \\Theta_0$, the the distribution of the stastic $-2 log(\\lambda(X))$ converges to chi-squared distribution as the sample size $n->\\infty$. The degree of freedom of thelimiting distribution is the difference between the number of free parameters specified by $\\theta \\in \\Theta_0$ and the number of free parameters specified by $\\theta \\in \\Theta$\n",
        "\n",
        "Ex: 10.3.4. Multinomial LRT\n",
        "\n"
      ],
      "metadata": {
        "id": "Sr72ebMCbRMP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Other Large-Sample Tests\n",
        "\n",
        "ex: 10.3.5. Large-sample binomial tests\n",
        "\n",
        "ex: 10.3.6. Binomial score test\n",
        "\n"
      ],
      "metadata": {
        "id": "0BiQovaybROl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Interval Estyimation\n",
        "\n"
      ],
      "metadata": {
        "id": "41vgXDdXbRQy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Approximate Maximum Likelihood Intervals\n",
        "\n",
        "ex: 10.4.2. Binomial score interval\n",
        "\n",
        "ex: 10.4.3. Binomial LRT interval\n",
        "\n"
      ],
      "metadata": {
        "id": "CPg74cKObRS3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Other Large Sample Intervals\n",
        "\n",
        "Ex: 10.4.4. Approximate interval\n",
        "\n",
        "ex: 10.4.5. Approximate Poisson interval\n",
        "\n",
        "ex: 10.4.6. More on the binomial score interval\n",
        "\n",
        "ex: 10.4.7. COmparison of binomial intervals\n",
        "\n",
        "ex: 10.4.8. Intervals based on the Huber estimator\n",
        "\n",
        "ex: Negative Binomial interval\n",
        "\n"
      ],
      "metadata": {
        "id": "jyEHE0FybRVF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "BOLPuVPcbRXx"
      }
    }
  ]
}